#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
os.environ["CUDA_VISIBLE_DEVICES"]='1'
import sys
from tqdm import tqdm
from os.path import join, dirname
sys.path.insert(0, join(dirname(__file__), '..'))
sys.path.insert(0, join(dirname(__file__), '../../'))

import random
import argparse
import numpy as np
from PIL import Image
from datetime import datetime
import time

import torch
from torch.autograd import Variable
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from torchvision.utils import save_image
torch.backends.cudnn.benchmark = True


from models import GeneratorUNet, GeneratorCNN ,Discriminator
from dataset import CARLADataset
from utils import write_params

random.seed(datetime.now())
torch.manual_seed(214202)
torch.cuda.manual_seed(214202)
torch.set_num_threads(32)

parser = argparse.ArgumentParser()
parser.add_argument('--eval', type=bool, default=False, help='if eval')
parser.add_argument('--epoch', type=int, default=0, help='epoch to start training from')
parser.add_argument('--init_step', type=int, default=-1, help='epoch to start training from')
parser.add_argument('--init_model', type=int, default=0, help='epoch to start training from')
parser.add_argument('--n_epochs', type=int, default=100, help='number of epochs of training')
parser.add_argument('--test_split', type=float, default=0.01, help='Split rate to divide test dataset and train dataset')
parser.add_argument('--dataset_name', type=str, default="cgan-human-data-05-test", help='name of the dataset')
parser.add_argument('--batch_size', type=int, default=32, help='size of the batches')
parser.add_argument('--lr', type=float, default=3e-6, help='adam: learning rate')
parser.add_argument('--b1', type=float, default=0.5, help='adam: decay of first order momentum of gradient')
parser.add_argument('--b2', type=float, default=0.999, help='adam: decay of first order momentum of gradient')
parser.add_argument('--decay_epoch', type=int, default=30, help='epoch from which to start lr decay')
parser.add_argument('--n_cpu', type=int, default=16, help='number of cpu threads to use during batch generation')
parser.add_argument('--n_prefetch', type=int, default=2, help='number of samples to load in advance')
parser.add_argument('--img_height', type=int, default=128, help='size of image height')
parser.add_argument('--img_width', type=int, default=256, help='size of image width')
parser.add_argument('--channels', type=int, default=3, help='number of image channels')
parser.add_argument('--sample_interval', type=int, default=1000, help='interval between sampling of images from generators')
parser.add_argument('--checkpoint_interval', type=int, default=1000, help='interval between model checkpoints')
parser.add_argument('--save_num', type=int, default=0, help='save path number')
parser.add_argument('--cgan_lambda', type=int, default=1, help='Loss weight of cGan')
parser.add_argument('--pixel_lambda', type=int, default=100, help='Loss weight of L1 pixel-wise loss between translated image and real image')
parser.add_argument('--core_lambda', type=int, default=100, help='Loss weight of L1 pixel-wise loss between core generated by S and G')
parser.add_argument('--loss_core', type=str, default='L2', help='Loss Function of core')
parser.add_argument('--generator', type=str, default='UNet', help='Generator kind')



opt = parser.parse_args()
#print(opt)

description = 'cgan train, dynamic obstacles'

save_path = './resultCostMap_seg/'+str(opt.save_num)+'/'
log_path = save_path+'/log/'+opt.dataset_name+'/'
os.makedirs(save_path+'/images/%s' % opt.dataset_name, exist_ok=True)
os.makedirs(save_path+'/saved_models/%s' % opt.dataset_name, exist_ok=True)

if not opt.eval:
    logger = SummaryWriter(log_dir=log_path)
    write_params(log_path, parser, description)
    

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print('device:',device)
# Loss functions
criterion_GAN = torch.nn.MSELoss()

if opt.loss_core == 'L1':
    criterion_core = torch.nn.L1Loss()
else:
    criterion_core = torch.nn.MSELoss()
criterion_seg = torch.nn.L1Loss()
criterion_pixelwise = torch.nn.L1Loss()

# Loss weight of L1 pixel-wise loss between translated image and real image
# Calculate output of image discriminator (PatchGAN)
patch = (1, opt.img_height//2**4, opt.img_width//2**4)

if opt.generator == 'UNet':
    generator = GeneratorUNet(in_channels=6,out_channels=1)
elif opt.generator == 'CNN':
    generator = GeneratorCNN(in_channels=6,out_channels=1)

discriminator = Discriminator()
segmentator = GeneratorUNet(in_channels=6,out_channels=1)



if opt.init_model == 0:
    pass
else:
    generator.load_state_dict(torch.load(save_path+'saved_models/%s/g_%d.pth'
                       % (opt.dataset_name, opt.init_step)))
    discriminator.load_state_dict(torch.load(save_path+'saved_models/%s/d_%d.pth'
                       % (opt.dataset_name, opt.init_step)))
    segmentator.load_state_dict(torch.load(save_path+'saved_models/%s/s_%d.pth'
                       % (opt.dataset_name, opt.init_step)))


generator = generator.to(device)
discriminator = discriminator.to(device)
segmentator = segmentator.to(device) 

criterion_GAN.to(device)
criterion_seg.to(device)
    
criterion_core.to(device)
criterion_pixelwise.to(device)
#unet encode

# Optimizers
optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))
optimizer_S = torch.optim.Adam(segmentator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))
optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))


print("loading dataset...")

index_list = [11,12,13,21,22,23,31,32,33,41,42,43,51,52,53,54]

train_dataset=CARLADataset(data_index=index_list,dataset_path='../datacollect/DATASET/CARLA/Segmentation/')
test_dataset=CARLADataset(data_index=[0],dataset_path='../datacollect/DATASET/CARLA/Segmentation/', eval_mode=True)

train_loader = DataLoader(train_dataset,
                            batch_size=opt.batch_size, shuffle=False, 
                            num_workers=opt.n_cpu,prefetch_factor=opt.n_prefetch,pin_memory=True)
test_dataloader = DataLoader(test_dataset,
                            batch_size=1, shuffle=False, 
                            num_workers=1,prefetch_factor=2)
test_samples = iter(test_dataloader)

def sample_images(steps):
    #Saves a generated sample from the validation set
    generator.eval()
    with torch.no_grad():
        test_batch = next(test_samples)
        img = test_batch['img']
        nav = test_batch['nav']
        fake_nav = test_batch['fake_nav']
        seg = test_batch['seg']
        label = test_batch['label']


        img_nav = torch.cat((img, nav), 1)
        seg_nav = torch.cat((seg, nav), 1)
    
        img_nav = Variable(img_nav).to(device)
        seg_nav = Variable(seg_nav).to(device)

        label = Variable(label).to(device)

        S_fake, _= segmentator(seg_nav)
        G_fake,_ = generator(img_nav)
        # print(len(vae_result))
    
        img_sample = torch.cat((img.data, nav.data), -2)
        img_sample = torch.cat((img_sample.data, seg.data), -2)

        pre_sample = torch.cat((S_fake.data, G_fake.data), -2)
        pre_sample = torch.cat((pre_sample, label.data), -2)
        

        img_fake_nav = torch.cat((img, fake_nav), 1)
        img_fake_nav = Variable(img_fake_nav).to(device)

        err_img_sample = torch.cat((img.data, fake_nav.data), -2)
        err_pre_sample = torch.cat((generator(img_fake_nav)[0].data, label.data), -2)
    
        #pre_sample = test_fake_b
    
        save_image(img_sample, save_path+'images/%s/%s_img.png' % (opt.dataset_name, steps), nrow=4, normalize=True)
        save_image(pre_sample, save_path+'images/%s/%s_pre.png' % (opt.dataset_name, steps), nrow=4, normalize=True)

        save_image(err_img_sample, save_path+'images/%s/%s_img_err.png' % (opt.dataset_name, steps), nrow=4, normalize=True)
        save_image(err_pre_sample, save_path+'images/%s/%s_pre_err.png' % (opt.dataset_name, steps), nrow=4, normalize=True)


    
    generator.train()

print('Start to train ...')
total_step = opt.init_step
for epoch in range(opt.epoch, opt.n_epochs):
    print(f"epoch: {epoch}")
    bar = enumerate(train_loader)
    length = len(train_loader)
    bar = tqdm(bar, total=length)
    for i, batch in bar:
        img_nav = batch['img_nav']
        label = batch['label']
        seg_nav = batch['seg_nav']
        fake_nav_with_img = batch['fake_nav_with_img']


        valid = Variable(torch.from_numpy(np.ones((opt.batch_size, *patch))).float(), requires_grad=False).to(device)
        fake = Variable(torch.from_numpy(np.zeros((opt.batch_size, *patch))).float(), requires_grad=False).to(device)
        # Model inputs
        img_nav= Variable(img_nav).to(device)
        label = Variable(label).to(device)
        seg_nav = Variable(seg_nav).to(device)
        fake_nav_with_img = Variable(fake_nav_with_img).to(device)


        # forward
        G_fake,G_core = generator(img_nav)
        G_fake_unpair,G_core_unpair=generator(fake_nav_with_img)
        S_fake,S_core = segmentator(seg_nav)
        S_fake_unpair,S_core_unpair=segmentator(fake_nav_with_img)

        pred_fake = discriminator(G_fake, img_nav)
        
        # S-loss and step:
        optimizer_S.zero_grad()
        loss_S = (1/(1+0.05))*(criterion_seg(S_fake, label)+0.05*criterion_seg(S_fake_unpair, label))
        loss_S.backward()
        torch.nn.utils.clip_grad_value_(generator.parameters(), clip_value=20)
        optimizer_S.step()

        # G- loss and step
        optimizer_G.zero_grad()
        # GAN loss
        # loss_GAN = criterion_GAN(pred_fake, valid)
        loss_GAN = 0.5 *(criterion_GAN(pred_fake, valid)+criterion_GAN(discriminator(G_fake_unpair, fake_nav_with_img), valid))
        # GAN loss
        loss_core = 0.5 * (criterion_core(G_core, S_core.detach())+criterion_core(G_core_unpair, S_core_unpair.detach()))
        # Pixel-wise loss
        # loss_pixel = criterion_pixelwise(G_fake, label)
        correct_pixel = criterion_pixelwise(G_fake, label)
        loss_pixel = (1/(1+0.05)) *( correct_pixel+0.05*criterion_pixelwise(G_fake_unpair, label))
        # Total loss
        loss_G = opt.cgan_lambda*loss_GAN + opt.core_lambda*loss_core + opt.pixel_lambda*loss_pixel
        # loss_G = loss_GAN + opt.pixel_lambda*loss_pixel

        #loss_G = loss_pixel
        loss_G.backward()
        torch.nn.utils.clip_grad_value_(generator.parameters(), clip_value=20)
        optimizer_G.step()
        
        # D- loss and step
        optimizer_D.zero_grad()
        # Real loss
        pred_real = discriminator(label, img_nav)
        loss_real = criterion_GAN(pred_real, valid)
        # Fake loss
        pred_fake = discriminator(G_fake.detach(), img_nav)
        loss_fake = criterion_GAN(pred_fake, fake)
        # Total loss
        loss_D = 0.5 * (loss_real + loss_fake)
        loss_D.backward()
        torch.nn.utils.clip_grad_value_(discriminator.parameters(), clip_value=20)
        optimizer_D.step()

        logger.add_scalar('loss/loss_D', loss_D.item(), total_step)
        logger.add_scalar('loss/loss_G', loss_G.item(), total_step)
        logger.add_scalar('loss/loss_S', loss_S.item(), total_step)

        logger.add_scalar('loss/loss_pixel', loss_pixel.item(), total_step)
        logger.add_scalar('loss/loss_core', loss_core.item(), total_step)
        logger.add_scalar('loss/loss_pixel_correct', correct_pixel.item(), total_step)


        logger.add_scalar('loss/loss_GAN', loss_GAN.item(), total_step)

        # If at sample interval save image
        if total_step % opt.sample_interval == 0:
            try:
                sample_images(total_step)
            except (StopIteration,NameError) :
                test_samples = iter(test_dataloader)
                sample_images(total_step)


        #if total_step % 500 == 0:
        #    for name, param in discriminator.named_parameters():
        #        logger.add_histogram('discriminator/'+name, param.clone().cpu().data.numpy(), total_step)
        #    for name, param in generator.named_parameters():
        #        logger.add_histogram('generator/'+name, param.clone().cpu().data.numpy(), total_step)

        if opt.checkpoint_interval != -1 and total_step % opt.checkpoint_interval == 0:
            # Save model checkpoints
            torch.save(generator.state_dict(), save_path+'saved_models/%s/g_%d.pth' %
                       (opt.dataset_name, total_step))
            torch.save(discriminator.state_dict(), save_path+'saved_models/%s/d_%d.pth'
                       % (opt.dataset_name, total_step))
            torch.save(segmentator.state_dict(), save_path+'saved_models/%s/s_%d.pth'
                       % (opt.dataset_name, total_step))
        total_step += 1
    
